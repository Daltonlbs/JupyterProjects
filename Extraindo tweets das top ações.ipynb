{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1c1cf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3ff83f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\dalto\\\\Desktop\\\\TCC\\\\Projeto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e87c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'Qkea9MJ2gz5RHczABY2Xsax0r'\n",
    "consumer_secret = 'ULNLPhJyBNbk23gWECGRekAxJHk49SuiKHMYbz55U83SFRNOoQ'\n",
    "access_token = '1483553041165037571-G4evKQ1uPCxWfEOYeY503opQksgsR5'\n",
    "access_token_secret = 'AD1VM0SrYIdqJPjHgJHmMLZnYh49ktbx6JxGmZH8K2mCa'\n",
    "\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tw.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f9787e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = pd.read_csv('TOPacoes080322.csv', sep = ',')\n",
    "#top.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "817b37a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>petr4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vale3</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prio3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  count\n",
       "0  petr4     40\n",
       "1  vale3     31\n",
       "2  prio3     22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = top[0:3]\n",
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41059a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(inst):\n",
    "    inst = re.sub(r\"http\\S+\", \"\", inst).lower().replace('.','').replace(',','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
    "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    palavras = [i for i in inst.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))\n",
    "\n",
    "def prep_tweets(tweet):\n",
    "    \n",
    "    tweet = BeautifulSoup(tweet, \"html.parser\").get_text()\n",
    "    tweet = re.sub(r\"[^a-zA-Z√†-√∫√Ä-√ö0-9]\", \" \", tweet.lower())\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be5e6081",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tt= pd.DataFrame()\n",
    "\n",
    "\n",
    "#search_words = \"VIIA3\" + \" -filter:retweets\"\n",
    "for w in top['word']:\n",
    "    data=[]\n",
    "    search_words = w + \" -filter:retweets\"\n",
    "   \n",
    "    c_tweets = tw.Cursor(api.search_tweets,\n",
    "                  q=search_words).items(10)\n",
    "    for tweet in c_tweets:\n",
    "        data.append([tweet.text])\n",
    "    tt[w]=data\"\"\";\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc9135be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt= pd.DataFrame()\n",
    "\n",
    "\n",
    "#search_words = \"VIIA3\" + \" -filter:retweets\"\n",
    "for w in top['word']:\n",
    "    data=[]\n",
    "    search_words = w + \" -filter:retweets\"\n",
    "   \n",
    "    c_tweets = tw.Cursor(api.search_tweets,\n",
    "                  q=search_words).items(10)\n",
    "    \n",
    "    for tweet in c_tweets:\n",
    "        Dtweets = Preprocessing(tweet.text)\n",
    "        #Dtweets = prep_tweets(Dtweets)\n",
    "        data.append(Dtweets)\n",
    "    \n",
    "    tt[w]=data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33f8158a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bbas3</th>\n",
       "      <th>vale3</th>\n",
       "      <th>trad3</th>\n",
       "      <th>petr4</th>\n",
       "      <th>ambp3</th>\n",
       "      <th>prio3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@andersonmeneses bbas3</td>\n",
       "      <td>@mariliadf2 exportadoras remetendo divisas jur...</td>\n",
       "      <td>conhece setup ponto cont√≠nuo (pc? tratase estr...</td>\n",
       "      <td>@mariliadf2 exportadoras remetendo divisas jur...</td>\n",
       "      <td>holdings gabarito ambp3 csan3 simh3 bpac11 vbb...</td>\n",
       "      <td>üìä m altas soma3 +780% r$ 1326 cogn3 749% r$ 24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ita√∫sa banco brasil hora vender manter comprar...</td>\n",
       "      <td>\"os fortes todos guerreiros dois tempo paci√™nc...</td>\n",
       "      <td>artigo hoje falamos sobre etfs criptomoedas op...</td>\n",
       "      <td>porque cota√ß√£o online broadcast comecei acompa...</td>\n",
       "      <td>gostam bitcoins gosto small caps brasilagro (a...</td>\n",
       "      <td>‚¨áÔ∏è baixas #bidi11 (963% r$ 2385 #amer3 (540% r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ainda sobre banco brasil #bbas3 futuro mostra ...</td>\n",
       "      <td>an√°lise ibov wing22 wdoh22 petr4 vale3 prio3 b...</td>\n",
       "      <td>guys! mau trad3 ke tae wings dvd ada gak ya?ü•∫ ...</td>\n",
       "      <td>@fernando_nassif porque cota√ß√£o online broadca...</td>\n",
       "      <td>foco guide recomenda compra ambipar #ambp3 pre...</td>\n",
       "      <td>‚¨ÜÔ∏è altas #flry3 (+824% r$ 1919 #soma3 (+732% r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p/vpa banco brasil #bbas3 ‚Ä¢ 31/12/2021 = 061 ‚Ä¢...</td>\n",
       "      <td>üëÄüá∑üá∫tens√£o r√∫ssia ocidente pode favorecer vale ...</td>\n",
       "      <td>#s2r trad3 #megalinks</td>\n",
       "      <td>@gu_rebel a√≠ brasil toma bunda pol√≠tica pre√ßos...</td>\n",
       "      <td>ambipar #ambp3 deve diminuir ritmo aquisi√ß√µes ...</td>\n",
       "      <td>an√°lise ibov wing22 wdoh22 petr4 vale3 prio3 b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>banco brasil (bbas3 lucro l√≠quido r$ 21 bi hor...</td>\n",
       "      <td>3 sess√µes baixa seguidas #ibov fechou dia alta...</td>\n",
       "      <td>cravada hist√≥rica empiricus short #trad3</td>\n",
       "      <td>an√°lise ibov wing22 wdoh22 petr4 vale3 prio3 b...</td>\n",
       "      <td>@costaassuero lembrando dia saiu not√≠cia cance...</td>\n",
       "      <td>üìäüìâmaiores baixa bidi11 963% amer3 540% embr3 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               bbas3  \\\n",
       "0                             @andersonmeneses bbas3   \n",
       "1  ita√∫sa banco brasil hora vender manter comprar...   \n",
       "2  ainda sobre banco brasil #bbas3 futuro mostra ...   \n",
       "3  p/vpa banco brasil #bbas3 ‚Ä¢ 31/12/2021 = 061 ‚Ä¢...   \n",
       "4  banco brasil (bbas3 lucro l√≠quido r$ 21 bi hor...   \n",
       "\n",
       "                                               vale3  \\\n",
       "0  @mariliadf2 exportadoras remetendo divisas jur...   \n",
       "1  \"os fortes todos guerreiros dois tempo paci√™nc...   \n",
       "2  an√°lise ibov wing22 wdoh22 petr4 vale3 prio3 b...   \n",
       "3  üëÄüá∑üá∫tens√£o r√∫ssia ocidente pode favorecer vale ...   \n",
       "4  3 sess√µes baixa seguidas #ibov fechou dia alta...   \n",
       "\n",
       "                                               trad3  \\\n",
       "0  conhece setup ponto cont√≠nuo (pc? tratase estr...   \n",
       "1  artigo hoje falamos sobre etfs criptomoedas op...   \n",
       "2  guys! mau trad3 ke tae wings dvd ada gak ya?ü•∫ ...   \n",
       "3                              #s2r trad3 #megalinks   \n",
       "4           cravada hist√≥rica empiricus short #trad3   \n",
       "\n",
       "                                               petr4  \\\n",
       "0  @mariliadf2 exportadoras remetendo divisas jur...   \n",
       "1  porque cota√ß√£o online broadcast comecei acompa...   \n",
       "2  @fernando_nassif porque cota√ß√£o online broadca...   \n",
       "3  @gu_rebel a√≠ brasil toma bunda pol√≠tica pre√ßos...   \n",
       "4  an√°lise ibov wing22 wdoh22 petr4 vale3 prio3 b...   \n",
       "\n",
       "                                               ambp3  \\\n",
       "0  holdings gabarito ambp3 csan3 simh3 bpac11 vbb...   \n",
       "1  gostam bitcoins gosto small caps brasilagro (a...   \n",
       "2  foco guide recomenda compra ambipar #ambp3 pre...   \n",
       "3  ambipar #ambp3 deve diminuir ritmo aquisi√ß√µes ...   \n",
       "4  @costaassuero lembrando dia saiu not√≠cia cance...   \n",
       "\n",
       "                                               prio3  \n",
       "0  üìä m altas soma3 +780% r$ 1326 cogn3 749% r$ 24...  \n",
       "1  ‚¨áÔ∏è baixas #bidi11 (963% r$ 2385 #amer3 (540% r...  \n",
       "2  ‚¨ÜÔ∏è altas #flry3 (+824% r$ 1919 #soma3 (+732% r...  \n",
       "3  an√°lise ibov wing22 wdoh22 petr4 vale3 prio3 b...  \n",
       "4  üìäüìâmaiores baixa bidi11 963% amer3 540% embr3 4...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2fae4bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëÄüá∑üá∫tens√£o r√∫ssia ocidente pode favorecer vale pressionar pre√ßo n√≠quel segundo analistas btg \"‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "print(tt.iloc[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6189a72c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af998fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "46f4e16e",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'latin-1' codec can't encode character '\\U0001f631' in position 89: ordinal not in range(256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-87782f6d7e7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TOPtts140222.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# , encoding='latin1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3385\u001b[0m         )\n\u001b[0;32m   3386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3387\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3388\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3389\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         )\n\u001b[1;32m-> 1083\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    246\u001b[0m             )\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_need_to_save_header\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_save_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36m_save_body\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstart_i\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[0mix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mslicer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format_native_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_number_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m         \u001b[0mlibwriters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_csv_rows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mpandas\\_libs\\writers.pyx\u001b[0m in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'latin-1' codec can't encode character '\\U0001f631' in position 89: ordinal not in range(256)"
     ]
    }
   ],
   "source": [
    "tt.to_csv('TOPtts140222.csv', index = False, encoding='latin1') # , encoding='latin1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8775beb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1572c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()  #Converte uma cole√ß√£o de textos em uma matrix de tokens\n",
    "count_matrix = cv.fit_transform(IDD) #Dtweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca72da80",
   "metadata": {},
   "outputs": [],
   "source": [
    "XXX = pd.DataFrame(cv.get_feature_names(), columns = ['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2938f1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7050d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetTokenizer = TweetTokenizer()\n",
    "tweets_tokenized = [tweetTokenizer.tokenize(tweet) for tweet in df.tweet]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
