{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99af4e4b",
   "metadata": {},
   "source": [
    "# Passo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "d2573a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn.metrics as metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "062b46d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1376,
   "id": "85dbcc06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\dalto\\\\Desktop\\\\Est√°gio\\\\Data Science\")\n",
    "\n",
    "dol = pd.read_csv(\"Dados_Dolar3.csv\", sep = \";\")\n",
    "#dol = pd.read_excel(\"PredDolarInv4.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1377,
   "id": "509cd7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abertura</th>\n",
       "      <th>Maxima</th>\n",
       "      <th>Minima</th>\n",
       "      <th>Fechamento</th>\n",
       "      <th>DI25</th>\n",
       "      <th>OURO</th>\n",
       "      <th>WTIBRENT</th>\n",
       "      <th>DXY</th>\n",
       "      <th>MXN</th>\n",
       "      <th>T10USA</th>\n",
       "      <th>BollingerSup</th>\n",
       "      <th>BollingerInf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-28</th>\n",
       "      <td>3522020</td>\n",
       "      <td>3535960</td>\n",
       "      <td>3515320</td>\n",
       "      <td>3535960</td>\n",
       "      <td>10300</td>\n",
       "      <td>1310490</td>\n",
       "      <td>46780</td>\n",
       "      <td>92170</td>\n",
       "      <td>17610</td>\n",
       "      <td>2159</td>\n",
       "      <td>3594860</td>\n",
       "      <td>3499860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-29</th>\n",
       "      <td>3527590</td>\n",
       "      <td>3544880</td>\n",
       "      <td>3524800</td>\n",
       "      <td>3532060</td>\n",
       "      <td>10250</td>\n",
       "      <td>1309500</td>\n",
       "      <td>46310</td>\n",
       "      <td>91620</td>\n",
       "      <td>17816</td>\n",
       "      <td>2129</td>\n",
       "      <td>3595200</td>\n",
       "      <td>3501940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-30</th>\n",
       "      <td>3534840</td>\n",
       "      <td>3542090</td>\n",
       "      <td>3521460</td>\n",
       "      <td>3527040</td>\n",
       "      <td>10240</td>\n",
       "      <td>1308760</td>\n",
       "      <td>45940</td>\n",
       "      <td>92250</td>\n",
       "      <td>17713</td>\n",
       "      <td>2136</td>\n",
       "      <td>3593870</td>\n",
       "      <td>3506690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>3536480</td>\n",
       "      <td>3538150</td>\n",
       "      <td>3502030</td>\n",
       "      <td>3512590</td>\n",
       "      <td>10110</td>\n",
       "      <td>1322070</td>\n",
       "      <td>47080</td>\n",
       "      <td>92560</td>\n",
       "      <td>17710</td>\n",
       "      <td>2120</td>\n",
       "      <td>3591930</td>\n",
       "      <td>3510760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09</th>\n",
       "      <td>3504250</td>\n",
       "      <td>3510920</td>\n",
       "      <td>3483140</td>\n",
       "      <td>3504810</td>\n",
       "      <td>10160</td>\n",
       "      <td>1324970</td>\n",
       "      <td>47330</td>\n",
       "      <td>92100</td>\n",
       "      <td>17760</td>\n",
       "      <td>2166</td>\n",
       "      <td>3592310</td>\n",
       "      <td>3509830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Abertura   Maxima   Minima  Fechamento   DI25     OURO  WTIBRENT  \\\n",
       "Data                                                                           \n",
       "2017-08-28   3522020  3535960  3515320     3535960  10300  1310490     46780   \n",
       "2017-08-29   3527590  3544880  3524800     3532060  10250  1309500     46310   \n",
       "2017-08-30   3534840  3542090  3521460     3527040  10240  1308760     45940   \n",
       "2017-08-31   3536480  3538150  3502030     3512590  10110  1322070     47080   \n",
       "2017-01-09   3504250  3510920  3483140     3504810  10160  1324970     47330   \n",
       "\n",
       "              DXY    MXN  T10USA  BollingerSup  BollingerInf  \n",
       "Data                                                          \n",
       "2017-08-28  92170  17610    2159       3594860       3499860  \n",
       "2017-08-29  91620  17816    2129       3595200       3501940  \n",
       "2017-08-30  92250  17713    2136       3593870       3506690  \n",
       "2017-08-31  92560  17710    2120       3591930       3510760  \n",
       "2017-01-09  92100  17760    2166       3592310       3509830  "
      ]
     },
     "execution_count": 1377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dol[\"Data\"] = pd.to_datetime(dol[\"Data\"]).dt.normalize()\n",
    "dol = dol.set_index(\"Data\")\n",
    "dol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1378,
   "id": "f8d52b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dol=dol.div(1000)\n",
    "dol = dol.replace(0, np.NaN)\n",
    "dol = dol.fillna(method = \"ffill\")\n",
    "dol.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1379,
   "id": "655c463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dol[\"OURO\"] = dol[\"OURO\"].pct_change(1)#*100\n",
    "dol[\"OURO-1\"] = dol[\"OURO\"].shift(1)\n",
    "dol[\"OURO-2\"] = dol[\"OURO\"].shift(2)\n",
    "dol[\"OURO-3\"] = dol[\"OURO\"].shift(3)\n",
    "dol[\"OURO-4\"] = dol[\"OURO\"].shift(4)\n",
    "dol[\"OURO-5\"] = dol[\"OURO\"].shift(5)\n",
    "\n",
    "#dol[\"DXY\"] = dol[\"DXY\"].pct_change(1)#*100\n",
    "dol[\"DXY-1\"] = dol[\"DXY\"].shift(1)\n",
    "dol[\"DXY-2\"] = dol[\"DXY\"].shift(2)\n",
    "dol[\"DXY-3\"] = dol[\"DXY\"].shift(3)\n",
    "dol[\"DXY-4\"] = dol[\"DXY\"].shift(4)\n",
    "dol[\"DXY-5\"] = dol[\"DXY\"].shift(5)\n",
    "\n",
    "#dol[\"WTIBRENT\"] = dol[\"WTIBRENT\"].pct_change(1)#*100\n",
    "dol[\"WTIBRENT-1\"] = dol[\"WTIBRENT\"].shift(1)\n",
    "dol[\"WTIBRENT-2\"] = dol[\"WTIBRENT\"].shift(2)\n",
    "dol[\"WTIBRENT-3\"] = dol[\"WTIBRENT\"].shift(3)\n",
    "dol[\"WTIBRENT-4\"] = dol[\"WTIBRENT\"].shift(4)\n",
    "dol[\"WTIBRENT-5\"] = dol[\"WTIBRENT\"].shift(5)\n",
    "\n",
    "#dol[\"MXN\"] = dol[\"MXN\"].pct_change(1)#*100\n",
    "dol[\"MXN-1\"] = dol[\"MXN\"].shift(1)\n",
    "dol[\"MXN-2\"] = dol[\"MXN\"].shift(2)\n",
    "dol[\"MXN-3\"] = dol[\"MXN\"].shift(3)\n",
    "dol[\"MXN-4\"] = dol[\"MXN\"].shift(4)\n",
    "dol[\"MXN-5\"] = dol[\"MXN\"].shift(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1380,
   "id": "71d64f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "per = 1\n",
    "\n",
    "#dol[\"Alvo\"] = np.where(dol[\"Fechamento\"].shift(-1) > dol[\"Fechamento\"] , \"Alta\", \"Baixa\")\n",
    "dol[\"Alvo\"] = np.where(dol[\"Fechamento\"].shift(-1) > dol[\"Fechamento\"] , 1, 0)\n",
    "\n",
    "dol[\"Retorno\"] = dol[\"Fechamento\"].pct_change(per)\n",
    "dol[\"Retorno-1\"] = dol[\"Retorno\"].shift(1)\n",
    "dol[\"Retorno-2\"] = dol[\"Retorno-1\"].shift(1)\n",
    "dol[\"Retorno-3\"] = dol[\"Retorno-2\"].shift(1) \n",
    "\n",
    "dol[\"DistBoll\"] = (dol[\"BollingerSup\"] - dol[\"BollingerInf\"])\n",
    "dol[\"MMDistBoll5\"] = dol[\"DistBoll\"].rolling(5).mean()\n",
    "dol[\"MMDistBoll15\"] = dol[\"DistBoll\"].rolling(15).mean()\n",
    "#dol[\"DistBoll\"] = pd.qcut(dol[\"DistBoll\"], 10, labels = False)\n",
    "dol[\"DistBoll-1\"] = dol[\"DistBoll\"].shift(1)\n",
    "dol[\"DistBoll-2\"] = dol[\"DistBoll\"].shift(2)\n",
    "dol[\"DistBoll-3\"] = dol[\"DistBoll\"].shift(3)\n",
    "#dol[\"DistBoll-4\"] = dol[\"DistBoll\"].shift(4)\n",
    "#dol[\"DistBoll-5\"] = dol[\"DistBoll\"].shift(5)\n",
    "\n",
    "# Desvio Padr√£o\n",
    "dol[\"std5\"] = dol[\"Fechamento\"].rolling(5).std()\n",
    "dol[\"std15\"] = dol[\"Fechamento\"].rolling(15).std()\n",
    "\n",
    "# Propor√ß√£o do corpo do candle em rela√ß√£o ao range do dia\n",
    "dol[\"prop\"] = (dol[\"Fechamento\"]-dol[\"Abertura\"])/(dol[\"Maxima\"]-dol[\"Minima\"])\n",
    "\n",
    "# Dire√ß√£o do dia atual\n",
    "dol[\"dirD\"] = np.where(dol[\"Fechamento\"] > dol[\"Abertura\"], 1, 0)\n",
    "dol[\"dirD-1\"] = dol[\"dirD\"].shift(1)\n",
    "dol[\"dirD-2\"] = dol[\"dirD\"].shift(2)\n",
    "dol[\"dirD-3\"] = dol[\"dirD\"].shift(3)\n",
    "#dol[\"dirD-4\"] = dol[\"dirD\"].shift(4)\n",
    "#dol[\"dirD-5\"] = dol[\"dirD\"].shift(5)\n",
    "\n",
    "# M√©dia m√≥vel de 15 dias\n",
    "dol[\"MM\"] = dol[\"Fechamento\"].rolling(15).mean()\n",
    "\n",
    "# Zscore\n",
    "dol[\"zscore\"] = (dol[\"Fechamento\"]-dol[\"MM\"])/dol[\"std15\"]\n",
    "dol[\"zscore-1\"] = dol[\"zscore\"].shift(1)\n",
    "dol[\"zscore-2\"] = dol[\"zscore\"].shift(2)\n",
    "dol[\"zscore-3\"] = dol[\"zscore\"].shift(3)\n",
    "#dol[\"zscore-4\"] = dol[\"zscore\"].shift(4)\n",
    "#dol[\"zscore-5\"] = dol[\"zscore\"].shift(5)\n",
    "\n",
    "# RSL\n",
    "dol[\"RSL\"] = (dol[\"Fechamento\"]/dol[\"MM\"])-1\n",
    "\n",
    "\n",
    "dol[\"Pips\"] = (dol[\"Fechamento\"].shift(1) - dol[\"Fechamento\"])\n",
    "dol[\"Pips-1\"] = dol[\"Pips\"].shift(1)\n",
    "dol[\"Pips-2\"] = dol[\"Pips\"].shift(2)\n",
    "dol[\"Pips-3\"] = dol[\"Pips\"].shift(3)\n",
    "#dol[\"Pips-4\"] = dol[\"Pips\"].shift(4)\n",
    "#dol[\"Pips-5\"] = dol[\"Pips\"].shift(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1381,
   "id": "38cce46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dol[\"std5\"] = pd.qcut(dol[\"std5\"], 10, labels = False)\n",
    "dol[\"std15\"] = pd.qcut(dol[\"std15\"], 10, labels = False)\n",
    "#dol[\"DI25\"] = pd.qcut(dol[\"DI25\"], 10, labels = False)\n",
    "#dol[\"T10USA\"] = pd.qcut(dol[\"T10USA\"], 10, labels = False)\n",
    "dol[\"prop\"] = pd.qcut(dol[\"prop\"], 10, labels = False)\n",
    "dol[\"prop-1\"] = dol[\"prop\"].shift(1)\n",
    "dol[\"prop-2\"] = dol[\"prop\"].shift(2)\n",
    "dol[\"prop-3\"] = dol[\"prop\"].shift(3)\n",
    "#dol[\"prop-5\"] = dol[\"prop\"].shift(4)\n",
    "#dol[\"prop-4\"] = dol[\"prop\"].shift(5)\n",
    "dol[\"MMDistBoll15\"] = pd.qcut(dol[\"MMDistBoll15\"], 10, labels = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1382,
   "id": "98994bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dol.isna().sum().sum()\n",
    "dol=dol.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1383,
   "id": "f77ef7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DI25', 'OURO', 'WTIBRENT', 'DXY', 'MXN', 'T10USA', 'BollingerSup',\n",
       "       'BollingerInf', 'OURO-1', 'OURO-2', 'OURO-3', 'OURO-4', 'OURO-5',\n",
       "       'DXY-1', 'DXY-2', 'DXY-3', 'DXY-4', 'DXY-5', 'WTIBRENT-1', 'WTIBRENT-2',\n",
       "       'WTIBRENT-3', 'WTIBRENT-4', 'WTIBRENT-5', 'MXN-1', 'MXN-2', 'MXN-3',\n",
       "       'MXN-4', 'MXN-5', 'Alvo', 'Retorno', 'Retorno-1', 'Retorno-2',\n",
       "       'Retorno-3', 'DistBoll', 'MMDistBoll5', 'MMDistBoll15', 'DistBoll-1',\n",
       "       'DistBoll-2', 'DistBoll-3', 'std5', 'std15', 'prop', 'dirD', 'dirD-1',\n",
       "       'dirD-2', 'dirD-3', 'zscore', 'zscore-1', 'zscore-2', 'zscore-3', 'RSL',\n",
       "       'Pips', 'Pips-1', 'Pips-2', 'Pips-3', 'prop-1', 'prop-2', 'prop-3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dol = dol.drop([\"Abertura\", \"Fechamento\", \"Minima\", \"Maxima\", \"MM\"], axis = 1)\n",
    "dol.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1384,
   "id": "5bd82977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 58)\n",
      "(238, 58)\n"
     ]
    }
   ],
   "source": [
    "# Treinamento de 2017 a 2020.1\n",
    "sTrain = \"2017-08-28\"\n",
    "eTrain = \"2020-06-30\"\n",
    "# Teste de 2020.2 at√© agora \n",
    "sTest = \"2020-07-01\" #\"2020-07-01\"\n",
    "eTest = \"2021-07-05\"\n",
    "\n",
    "# dfTrain = dff[dff[\"Data\"] <= eTrain]\n",
    "# dfTest = dff[dff[\"Data\"] > eTrain]\n",
    "\n",
    "dfTrain = dol.loc[sTrain : eTrain]\n",
    "dfTest  = dol.loc[sTest  : eTest]\n",
    "print(dfTrain.shape)\n",
    "print(dfTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1385,
   "id": "e32e0326",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = dfTrain.drop([\"Alvo\"], axis = 1)\n",
    "yTrain = dfTrain[\"Alvo\"]\n",
    "\n",
    "xTest = dfTest.drop([\"Alvo\"], axis = 1)\n",
    "yTest = dfTest[\"Alvo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1398,
   "id": "b435ac15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.74058133\n",
      "Iteration 2, loss = 0.72042058\n",
      "Iteration 3, loss = 0.70846658\n",
      "Iteration 4, loss = 0.70151166\n",
      "Iteration 5, loss = 0.69824013\n",
      "Iteration 6, loss = 0.69701275\n",
      "Iteration 7, loss = 0.69448430\n",
      "Iteration 8, loss = 0.69355258\n",
      "Iteration 9, loss = 0.69270807\n",
      "Iteration 10, loss = 0.69153305\n",
      "Iteration 11, loss = 0.69117831\n",
      "Iteration 12, loss = 0.69074564\n",
      "Iteration 13, loss = 0.69037392\n",
      "Iteration 14, loss = 0.69039898\n",
      "Iteration 15, loss = 0.69050540\n",
      "Iteration 16, loss = 0.69086626\n",
      "Iteration 17, loss = 0.69016096\n",
      "Iteration 18, loss = 0.69051602\n",
      "Iteration 19, loss = 0.69074343\n",
      "Iteration 20, loss = 0.69026772\n",
      "Iteration 21, loss = 0.69013433\n",
      "Iteration 22, loss = 0.69050359\n",
      "Iteration 23, loss = 0.69032994\n",
      "Iteration 24, loss = 0.69039984\n",
      "Iteration 25, loss = 0.69005032\n",
      "Iteration 26, loss = 0.69030453\n",
      "Iteration 27, loss = 0.69000477\n",
      "Iteration 28, loss = 0.68984760\n",
      "Iteration 29, loss = 0.68983487\n",
      "Iteration 30, loss = 0.68993812\n",
      "Iteration 31, loss = 0.68983602\n",
      "Iteration 32, loss = 0.68994568\n",
      "Iteration 33, loss = 0.69007652\n",
      "Iteration 34, loss = 0.68999385\n",
      "Iteration 35, loss = 0.69000867\n",
      "Iteration 36, loss = 0.68977146\n",
      "Iteration 37, loss = 0.69003374\n",
      "Iteration 38, loss = 0.68990414\n",
      "Iteration 39, loss = 0.68996417\n",
      "Iteration 40, loss = 0.69014187\n",
      "Iteration 41, loss = 0.68987861\n",
      "Iteration 42, loss = 0.68962099\n",
      "Iteration 43, loss = 0.68977745\n",
      "Iteration 44, loss = 0.69001775\n",
      "Iteration 45, loss = 0.68921179\n",
      "Iteration 46, loss = 0.68960891\n",
      "Iteration 47, loss = 0.68969605\n",
      "Iteration 48, loss = 0.68966041\n",
      "Iteration 49, loss = 0.68955407\n",
      "Iteration 50, loss = 0.68952796\n",
      "Iteration 51, loss = 0.68959390\n",
      "Iteration 52, loss = 0.68972957\n",
      "Iteration 53, loss = 0.68952643\n",
      "Iteration 54, loss = 0.68941195\n",
      "Iteration 55, loss = 0.68964926\n",
      "Iteration 56, loss = 0.68947814\n",
      "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Setting learning rate to 0.000010\n",
      "Iteration 57, loss = 0.68963765\n",
      "Iteration 58, loss = 0.68951741\n",
      "Iteration 59, loss = 0.68935286\n",
      "Iteration 60, loss = 0.68936730\n",
      "Iteration 61, loss = 0.68922717\n",
      "Iteration 62, loss = 0.68907603\n",
      "Iteration 63, loss = 0.68907928\n",
      "Iteration 64, loss = 0.68903382\n",
      "Iteration 65, loss = 0.68900487\n",
      "Iteration 66, loss = 0.68899338\n",
      "Iteration 67, loss = 0.68900647\n",
      "Iteration 68, loss = 0.68901457\n",
      "Iteration 69, loss = 0.68899560\n",
      "Iteration 70, loss = 0.68899220\n",
      "Iteration 71, loss = 0.68900020\n",
      "Iteration 72, loss = 0.68898172\n",
      "Iteration 73, loss = 0.68895280\n",
      "Iteration 74, loss = 0.68895177\n",
      "Iteration 75, loss = 0.68892003\n",
      "Iteration 76, loss = 0.68893448\n",
      "Iteration 77, loss = 0.68893853\n",
      "Iteration 78, loss = 0.68893771\n",
      "Iteration 79, loss = 0.68894258\n",
      "Iteration 80, loss = 0.68891495\n",
      "Iteration 81, loss = 0.68897551\n",
      "Iteration 82, loss = 0.68892867\n",
      "Iteration 83, loss = 0.68887566\n",
      "Iteration 84, loss = 0.68880041\n",
      "Iteration 85, loss = 0.68872592\n",
      "Iteration 86, loss = 0.68879586\n",
      "Iteration 87, loss = 0.68879572\n",
      "Iteration 88, loss = 0.68873681\n",
      "Iteration 89, loss = 0.68873072\n",
      "Iteration 90, loss = 0.68872493\n",
      "Iteration 91, loss = 0.68877558\n",
      "Iteration 92, loss = 0.68872845\n",
      "Iteration 93, loss = 0.68872096\n",
      "Iteration 94, loss = 0.68868367\n",
      "Iteration 95, loss = 0.68868889\n",
      "Iteration 96, loss = 0.68872864\n",
      "Iteration 97, loss = 0.68868421\n",
      "Iteration 98, loss = 0.68871790\n",
      "Iteration 99, loss = 0.68869045\n",
      "Iteration 100, loss = 0.68870294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', hidden_layer_sizes=(200, 200, 200),\n",
       "              learning_rate='adaptive', learning_rate_init=5e-05, max_iter=100,\n",
       "              random_state=42, solver='sgd', tol=1e-08, verbose=10)"
      ]
     },
     "execution_count": 1398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes = (200,200,200), max_iter = 100,\n",
    "                   solver = \"sgd\", verbose = 10, tol = 1e-8, random_state=42,\n",
    "                   learning_rate_init = .00005, learning_rate = \"adaptive\", activation = \"tanh\") # activation = \"tanh\"\n",
    "\n",
    "mlp.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1399,
   "id": "0cb97277",
   "metadata": {},
   "outputs": [],
   "source": [
    "predTrain = mlp.predict(xTrain)\n",
    "predTest = mlp.predict(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1400,
   "id": "fc2eef17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[153 198]\n",
      " [131 226]]\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.44      0.48       351\n",
      "           1       0.53      0.63      0.58       357\n",
      "\n",
      "    accuracy                           0.54       708\n",
      "   macro avg       0.54      0.53      0.53       708\n",
      "weighted avg       0.54      0.54      0.53       708\n",
      "\n",
      "\n",
      "Acur√°cia:  53.531\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yTrain, predTrain))\n",
    "print()\n",
    "print(\"------------------------------------------------\")\n",
    "print()\n",
    "print(classification_report(yTrain,predTrain))\n",
    "\n",
    "print()\n",
    "print(\"Acur√°cia: \", round(metrics.accuracy_score(yTrain, predTrain)*100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1401,
   "id": "b9d2e341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51 67]\n",
      " [40 80]]\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.43      0.49       118\n",
      "           1       0.54      0.67      0.60       120\n",
      "\n",
      "    accuracy                           0.55       238\n",
      "   macro avg       0.55      0.55      0.54       238\n",
      "weighted avg       0.55      0.55      0.54       238\n",
      "\n",
      "\n",
      "Acur√°cia:  55.042\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yTest, predTest))\n",
    "print()\n",
    "print(\"------------------------------------------------\")\n",
    "print()\n",
    "print(classification_report(yTest,predTest))\n",
    "\n",
    "print()\n",
    "print(\"Acur√°cia: \", round(metrics.accuracy_score(yTest, predTest)*100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "id": "874d7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predTot = mlp.predict(dol.drop([\"Alvo\"], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "b20ac333",
   "metadata": {},
   "outputs": [],
   "source": [
    "dol.loc[:,\"Previsto\"] = predTot\n",
    "dol.loc[:,\"RetornoMod\"] = predTot = dol.loc[:,\"Previsto\"]*dol[\"Retorno\"]\n",
    "\n",
    "#simulando um stop de 3%\n",
    "\n",
    "stop = 0.02\n",
    "dol.loc[:,\"RetornoMod\"] = np.where(dol.loc[:,\"RetornoMod\"] < -stop, stop, dol.loc[:, \"RetornoMod\"])\n",
    "\n",
    "dol.loc[:,\"RetornoModAcum\"] = dol[\"RetornoMod\"].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "81da56e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data\n",
       "2021-06-29    0.920459\n",
       "2021-06-30    0.926512\n",
       "2021-01-07    0.942256\n",
       "2021-02-07    0.942256\n",
       "2021-05-07    0.942256\n",
       "Name: RetornoModAcum, dtype: float64"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dol.loc[:, \"RetornoModAcum\"].tail()\n",
    "#dff[\"RetornoModAcum\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "5500656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dol.index.name = \"Date\"\n",
    "dol.reset_index(inplace = True)\n",
    "dol[\"Date\"] = pd.to_datetime(dol[\"Date\"])\n",
    "dol[\"TrainTest\"] = np.where(dol[\"Date\"] > eTrain,1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "abadd919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>DI25</th>\n",
       "      <th>OURO</th>\n",
       "      <th>WTIBRENT</th>\n",
       "      <th>DXY</th>\n",
       "      <th>MXN</th>\n",
       "      <th>T10USA</th>\n",
       "      <th>BollingerSup</th>\n",
       "      <th>BollingerInf</th>\n",
       "      <th>OURO-1</th>\n",
       "      <th>...</th>\n",
       "      <th>Pips-5</th>\n",
       "      <th>prop-1</th>\n",
       "      <th>prop-2</th>\n",
       "      <th>prop-3</th>\n",
       "      <th>prop-5</th>\n",
       "      <th>prop-4</th>\n",
       "      <th>Previsto</th>\n",
       "      <th>RetornoMod</th>\n",
       "      <th>RetornoModAcum</th>\n",
       "      <th>TrainTest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-20</td>\n",
       "      <td>9.79</td>\n",
       "      <td>1301.15</td>\n",
       "      <td>50.3</td>\n",
       "      <td>91.53</td>\n",
       "      <td>17.64</td>\n",
       "      <td>2.273</td>\n",
       "      <td>3567.13</td>\n",
       "      <td>3459.41</td>\n",
       "      <td>1311.28</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows √ó 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  DI25     OURO  WTIBRENT    DXY    MXN  T10USA  BollingerSup  \\\n",
       "0 2017-09-20  9.79  1301.15      50.3  91.53  17.64   2.273       3567.13   \n",
       "\n",
       "   BollingerInf   OURO-1  ...  Pips-5  prop-1  prop-2  prop-3  prop-5  prop-4  \\\n",
       "0       3459.41  1311.28  ...  -11.11     5.0     9.0     0.0     1.0     6.0   \n",
       "\n",
       "   Previsto  RetornoMod  RetornoModAcum  TrainTest  \n",
       "0         0        -0.0            -0.0         -1  \n",
       "\n",
       "[1 rows x 67 columns]"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dol.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "6e70c3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bAgreg = dol.resample(\"M\", on = \"Date\").sum()\n",
    "bAgreg = dol.resample(\"W\", on = \"Date\").sum()\n",
    "bAgreg.loc[:, \"RetornoModAcum\"] = bAgreg[\"RetornoMod\"].cumsum()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "45ab478a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-559-9f7a82ecf5e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m#plt.text(\"2011-03-01\", 500, \"@daltonlbs\", **setup)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mbAgreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbAgreg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"TrainTest\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbAgreg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"TrainTest\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrafico\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    892\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mode.chained_assignment\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    895\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m                 \u001b[1;31m# gh-20949\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[1;34m(self, f, data)\u001b[0m\n\u001b[0;32m    926\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mapplying\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m         \"\"\"\n\u001b[1;32m--> 928\u001b[1;33m         \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[1;31m# group might be modified\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[0mgroup_axes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_is_indexed_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0mmutated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-559-9f7a82ecf5e0>\u001b[0m in \u001b[0;36mgrafico\u001b[1;34m(group)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgrafico\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"black\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Date\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0meTrain\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"blue\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mlw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRetornoModAcum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1440\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1442\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1443\u001b[0m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1444\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(figsize = (20,15))\n",
    "\n",
    "def grafico(group):\n",
    "    color = \"black\" if (group[\"TrainTest\"] < 0).all() else \"blue\"\n",
    "    lw = 4.0\n",
    "    ax.plot(group.index, group.RetornoModAcum, c = color, linewidth = lw)\n",
    "    plt.xlabel(\"Ano\", fontsize = 18)\n",
    "    plt.ylabel(\"Retorno Acumulado %\", fontsize = 18)\n",
    "    plt.title(\"Rede Neural Artificial WIN\", fontsize = 24)\n",
    "    #plt.axvline(x = eTrain, color = \"purple\", linestyle = \"--\", lw = 2)\n",
    "    setup = dict(size = 16, color = \"darkgreen\")\n",
    "    setup2 = dict(size = 14, color = \"black\")\n",
    "    #plt.text('2007-01-01', 500, \"Treinamento 2005-2010\", **setup)\n",
    "    #plt.text(\"2012-01-01\", 500, \"Teste: 2011-2020\", **setup)\n",
    "    #plt.text(\"2008-06-01\", 500, \"ret total 587%\", **setup)\n",
    "    #plt.text(\"2008-06-01\", 500, \"Ret Teste 218%\", **setup)\n",
    "    #plt.text(\"2011-03-01\", 500, \"@daltonlbs\", **setup)\n",
    "    \n",
    "bAgreg.groupby((bAgreg[\"TrainTest\"].shift() * bAgreg[\"TrainTest\"] < 0).cumsum()).apply(grafico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311b3a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
